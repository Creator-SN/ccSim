{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 交互式模型训练的样例\n",
    "- model: BERT\n",
    "- dataset: CNSTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.trainer import Trainer\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fct_loss: 损失函数类型, 共有三种`MSELoss`, `BCELoss`, `CrossEntropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./model/chinese_wwm_ext/vocab.txt')\n",
    "trainer = Trainer(tokenizer, \"CNSTS\", \"CNSTS\", padding_length=150, batch_size=64, batch_size_eval=128, eval_mode='dev')\n",
    "\n",
    "for i in trainer(fct_loss='BCELoss'):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Siamese模型训练的样例\n",
    "- model: ESIM\n",
    "- dataset: CNSTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.trainer import Trainer\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./model/chinese_wwm_ext/vocab.txt')\n",
    "trainer = Trainer(tokenizer, \"CNSTS\", \"ASAG\", model_name=\"sbert\",  model_type=\"siamese\", padding_length=256, batch_size=8, batch_size_eval=128, eval_mode='dev', task_name='SAS_ASAG_sbert')\n",
    "\n",
    "for i in trainer():\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 交互式模型SAS训练的样例\n",
    "- model: BERT\n",
    "- dataset: CNSTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.sas_trainer import Trainer\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./model/chinese_wwm_ext/vocab.txt')\n",
    "trainer = Trainer(tokenizer, \"CNSTSX\", \"SAS\", model_name='bert', padding_length=256, batch_size=8, batch_size_eval=512, eval_mode='dev', task_name='SAS_SAS_bert')\n",
    "\n",
    "for i in trainer(fct_loss='MSELoss'):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Siamese模型SAS训练的样例\n",
    "- model: SBERT\n",
    "- dataset: CNSTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.sas_trainer import Trainer\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lpc/miniconda3/envs/pcpower/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1642: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'vocab_file'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2387344/3459088725.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./model/chinese_wwm_ext/vocab.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CNSTSX\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CNSTS\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'msim'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'siamese'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dev'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAS_CNSTS_msim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfct_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'MSELoss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/ccSim/CC/sas_trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tokenizer, loader_name, data_path, model_name, model_type, from_pretrained, data_present_path, padding_length, batch_size, batch_size_eval, eval_mode, task_name)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpadding_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         self.dataloader_init(tokenizer, loader_name, data_path, model_type,\n\u001b[0m\u001b[1;32m     27\u001b[0m                              data_present_path, padding_length, batch_size, batch_size_eval, eval_mode)\n\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/ccSim/CC/sas_trainer.py\u001b[0m in \u001b[0;36mdataloader_init\u001b[0;34m(self, tokenizer, loader_name, data_path, model_type, data_present_path, padding_length, batch_size, batch_size_eval, eval_mode)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdataloader_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_present_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         d = AutoDataloader(tokenizer, loader_name, data_path,\n\u001b[0m\u001b[1;32m     38\u001b[0m                            model_type, data_present_path, padding_length)\n\u001b[1;32m     39\u001b[0m         self.train_loader, self.eval_loader = d(\n",
      "\u001b[0;32m~/repos/ccSim/CC/loader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tokenizer, loader_name, data_path, model_type, data_present_path, padding_length)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mloader_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'CNSTSX'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             self.train_set = CNSTSXDataset(\n\u001b[0;32m---> 35\u001b[0;31m                 tokenizer, self.data_path['train'], self.data_path['vocab_file'], padding_length=self.padding_length, model_type=self.model_type, shuffle=True)\n\u001b[0m\u001b[1;32m     36\u001b[0m             self.eval_set = CNSTSXDataset(\n\u001b[1;32m     37\u001b[0m                 tokenizer, self.data_path['dev'], self.data_path['vocab_file'], padding_length=self.padding_length, model_type=self.model_type, shuffle=False)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'vocab_file'"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./model/chinese_wwm_ext/vocab.txt')\n",
    "trainer = Trainer(tokenizer, \"CNSTSX\", \"CNSTSX\", model_name='msim', model_type='siamese', padding_length=150, batch_size=16, batch_size_eval=512, eval_mode='dev', task_name='SAS_CNSTSX_msim')\n",
    "\n",
    "for i in trainer(fct_loss='MSELoss'):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MSIM模型SAS训练的样例\n",
    "- model: MSIM\n",
    "- dataset: CNSTSX\n",
    "\n",
    "最佳参数:\n",
    "- SAS: A + B + 0.2(C + D)\n",
    "- ASAG: A + B + 0.2(C + D)\n",
    "- SFR: 0.1A + B + 0.2(C + D)\n",
    "- CNSTS: A + B + 0.2(C + D)\n",
    "\n",
    "FewShot最佳参数:\n",
    "- SAS: A + B + 0.2(C + D)\n",
    "- ASAG: 0.1A + 0.8B + 0.2(C + D)\n",
    "\n",
    "Fewshot Prompt Fine-tuning时 ASAG数据集需要1e-4学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.sas_trainer import Trainer\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./model/chinese_wwm_ext/vocab.txt')\n",
    "trainer = Trainer(tokenizer, \"CNSTSX\", \"SFR\", model_name='msim', model_type='siamese', padding_length=256, batch_size=8, batch_size_eval=256, eval_mode='dev', task_name='SAS_SFR_msim')\n",
    "\n",
    "for i in trainer(fct_loss='MSELoss'):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SIMCSE 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.cl_trainer import CLTrainer\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('./model/chinese_wwm_ext/vocab.txt')\n",
    "trainer = CLTrainer(tokenizer, \"SIMCSE_STS\", \"SAS\", model_name='simcse', model_type='siamese', padding_length=256, batch_size=16, batch_size_eval=256, eval_mode='dev', task_name='SIMCSE_SAS')\n",
    "\n",
    "for i in trainer(fct_loss='MSELoss'):\n",
    "    a = i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.prompt_trainer import PromptTrainer\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('./model/chinese_wwm_ext/vocab.txt')\n",
    "trainer = PromptTrainer(tokenizer, \"SASPrompt\", \"ASAGPrompt\", model_name='bertlm', padding_length=256, batch_size=16, batch_size_eval=256, eval_mode='dev', task_name='Prompt_ASAG')\n",
    "\n",
    "for i in trainer():\n",
    "    a = i\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('pcpower')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e1e097b6c3c5a2a39328ddbc7de6327b7bd71c15618bc750f041eecacee4167"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
