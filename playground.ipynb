{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 交互式模型训练的样例\n",
    "- model: BERT\n",
    "- dataset: CNSTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.trainer import Trainer\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fct_loss: 损失函数类型, 共有三种`MSELoss`, `BCELoss`, `CrossEntropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./model/chinese_wwm_ext/vocab.txt')\n",
    "trainer = Trainer(tokenizer, \"CNSTS\", \"CNSTS\", padding_length=150, batch_size=64, batch_size_eval=128, eval_mode='dev')\n",
    "\n",
    "for i in trainer(fct_loss='BCELoss'):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Siamese模型训练的样例\n",
    "- model: ESIM\n",
    "- dataset: CNSTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.trainer import Trainer\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./model/chinese_wwm_ext/vocab.txt')\n",
    "trainer = Trainer(tokenizer, \"CNSTS\", \"CNSTS\", model_name=\"esim\",  model_type=\"siamese\", padding_length=150, batch_size=64, batch_size_eval=128, eval_mode='dev', task_name='ESIM_Sim')\n",
    "\n",
    "for i in trainer():\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 交互式模型SAS训练的样例\n",
    "- model: BERT\n",
    "- dataset: CNSTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.sas_trainer import Trainer\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./model/chinese_wwm_ext/vocab.txt')\n",
    "trainer = Trainer(tokenizer, \"CNSTSX\", \"CNSTSX\", model_name='bert', padding_length=150, batch_size=64, batch_size_eval=512, eval_mode='dev', task_name='SAS_CNSTS_BERT')\n",
    "\n",
    "for i in trainer(fct_loss='MSELoss'):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 交互式模型SAS训练的样例\n",
    "- model: MSIM\n",
    "- dataset: CNSTSX\n",
    "\n",
    "最佳参数:\n",
    "- SAS: A + 0.5B + 0.2(C + D)\n",
    "- SFR: 0.1A + B + 0.2(C + D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.sas_trainer import Trainer\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lpc/miniconda3/envs/pcpower/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1642: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  warnings.warn(\n",
      "100%|██████████| 231/231 [00:00<00:00, 85848.33it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 121892.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoModel Choose Model: msim\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]/home/lpc/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/lpc/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:117: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "Train: 1/30: 100%|██████████| 15/15 [00:15<00:00,  1.05s/it, Pearson=0.151, R=0.151, RMSE=0.433, Spearman=0.194, scoresA=0.479, scoresB=0.838, scoresC=0.488, scoresD=0.567, train_error=0.355, train_loss=0.183]  \n",
      "Eval: 1: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, Pearson=0.201, R=0.201, RMSE=0.364, Spearman=0.228, eval_error=0.284, eval_loss=0.132, scoresA=0.468, scoresB=0.813, scoresC=0.499, scoresD=0.567]\n",
      "Train: 2/30: 100%|██████████| 15/15 [00:08<00:00,  1.81it/s, Pearson=0.0963, R=0.0963, RMSE=0.297, Spearman=0.129, scoresA=0.394, scoresB=0.506, scoresC=0.478, scoresD=0.499, train_error=0.212, train_loss=0.0864]\n",
      "Eval: 2: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s, Pearson=0.429, R=0.429, RMSE=0.217, Spearman=0.498, eval_error=0.181, eval_loss=0.0472, scoresA=0.377, scoresB=0.508, scoresC=0.47, scoresD=0.519]\n",
      "Train: 3/30: 100%|██████████| 15/15 [00:08<00:00,  1.80it/s, Pearson=0.536, R=0.536, RMSE=0.206, Spearman=0.567, scoresA=0.367, scoresB=0.543, scoresC=0.459, scoresD=0.481, train_error=0.147, train_loss=0.0414]\n",
      "Eval: 3: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s, Pearson=0.494, R=0.494, RMSE=0.205, Spearman=0.567, eval_error=0.162, eval_loss=0.0422, scoresA=0.351, scoresB=0.551, scoresC=0.458, scoresD=0.496]\n",
      "Train: 4/30: 100%|██████████| 15/15 [00:08<00:00,  1.78it/s, Pearson=0.67, R=0.67, RMSE=0.182, Spearman=0.668, scoresA=0.396, scoresB=0.57, scoresC=0.469, scoresD=0.474, train_error=0.133, train_loss=0.0321]   \n",
      "Eval: 4: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it, Pearson=0.491, R=0.491, RMSE=0.206, Spearman=0.562, eval_error=0.151, eval_loss=0.0424, scoresA=0.374, scoresB=0.568, scoresC=0.454, scoresD=0.49]\n",
      "Train: 5/30: 100%|██████████| 15/15 [00:15<00:00,  1.01s/it, Pearson=0.8, R=0.8, RMSE=0.148, Spearman=0.727, scoresA=0.404, scoresB=0.634, scoresC=0.45, scoresD=0.474, train_error=0.104, train_loss=0.0211]     \n",
      "Eval: 5: 100%|██████████| 1/1 [00:01<00:00,  1.69s/it, Pearson=0.511, R=0.511, RMSE=0.209, Spearman=0.513, eval_error=0.158, eval_loss=0.0438, scoresA=0.403, scoresB=0.575, scoresC=0.452, scoresD=0.487]\n",
      "Train: 6/30: 100%|██████████| 15/15 [00:13<00:00,  1.12it/s, Pearson=0.919, R=0.919, RMSE=0.0959, Spearman=0.813, scoresA=0.394, scoresB=0.609, scoresC=0.451, scoresD=0.462, train_error=0.0723, train_loss=0.00901]\n",
      "Eval: 6: 100%|██████████| 1/1 [00:01<00:00,  1.49s/it, Pearson=0.635, R=0.635, RMSE=0.183, Spearman=0.622, eval_error=0.134, eval_loss=0.0336, scoresA=0.386, scoresB=0.577, scoresC=0.447, scoresD=0.479]\n",
      "Train: 7/30: 100%|██████████| 15/15 [00:07<00:00,  2.05it/s, Pearson=0.948, R=0.948, RMSE=0.0773, Spearman=0.846, scoresA=0.396, scoresB=0.608, scoresC=0.443, scoresD=0.47, train_error=0.0599, train_loss=0.00582] \n",
      "Eval: 7: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s, Pearson=0.574, R=0.574, RMSE=0.205, Spearman=0.548, eval_error=0.154, eval_loss=0.0422, scoresA=0.389, scoresB=0.534, scoresC=0.443, scoresD=0.474]\n",
      "Train: 8/30: 100%|██████████| 15/15 [00:08<00:00,  1.80it/s, Pearson=0.948, R=0.948, RMSE=0.0772, Spearman=0.862, scoresA=0.397, scoresB=0.694, scoresC=0.434, scoresD=0.462, train_error=0.062, train_loss=0.00594] \n",
      "Eval: 8: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s, Pearson=0.658, R=0.658, RMSE=0.186, Spearman=0.647, eval_error=0.131, eval_loss=0.0344, scoresA=0.38, scoresB=0.607, scoresC=0.44, scoresD=0.472]\n",
      "Train: 9/30: 100%|██████████| 15/15 [00:08<00:00,  1.82it/s, Pearson=0.942, R=0.942, RMSE=0.0825, Spearman=0.869, scoresA=0.383, scoresB=0.546, scoresC=0.444, scoresD=0.44, train_error=0.0649, train_loss=0.0069]  \n",
      "Eval: 9: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, Pearson=0.638, R=0.638, RMSE=0.186, Spearman=0.612, eval_error=0.136, eval_loss=0.0346, scoresA=0.37, scoresB=0.556, scoresC=0.433, scoresD=0.458]\n",
      "Train: 10/30: 100%|██████████| 15/15 [00:08<00:00,  1.83it/s, Pearson=0.96, R=0.96, RMSE=0.0705, Spearman=0.908, scoresA=0.354, scoresB=0.688, scoresC=0.434, scoresD=0.451, train_error=0.0529, train_loss=0.00502]  \n",
      "Eval: 10: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s, Pearson=0.655, R=0.655, RMSE=0.178, Spearman=0.636, eval_error=0.129, eval_loss=0.0316, scoresA=0.351, scoresB=0.585, scoresC=0.427, scoresD=0.453]\n",
      "Train: 11/30: 100%|██████████| 15/15 [00:08<00:00,  1.82it/s, Pearson=0.948, R=0.948, RMSE=0.0781, Spearman=0.891, scoresA=0.346, scoresB=0.648, scoresC=0.42, scoresD=0.407, train_error=0.0613, train_loss=0.00597] \n",
      "Eval: 11: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s, Pearson=0.663, R=0.663, RMSE=0.183, Spearman=0.652, eval_error=0.125, eval_loss=0.0334, scoresA=0.327, scoresB=0.634, scoresC=0.416, scoresD=0.435]\n",
      "Train: 12/30: 100%|██████████| 15/15 [00:08<00:00,  1.86it/s, Pearson=0.958, R=0.958, RMSE=0.0706, Spearman=0.913, scoresA=0.349, scoresB=0.605, scoresC=0.402, scoresD=0.384, train_error=0.0534, train_loss=0.0049] \n",
      "Eval: 12: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s, Pearson=0.582, R=0.582, RMSE=0.203, Spearman=0.554, eval_error=0.158, eval_loss=0.0413, scoresA=0.32, scoresB=0.549, scoresC=0.401, scoresD=0.41]\n",
      "Train: 13/30: 100%|██████████| 15/15 [00:08<00:00,  1.78it/s, Pearson=0.935, R=0.935, RMSE=0.0867, Spearman=0.87, scoresA=0.336, scoresB=0.721, scoresC=0.382, scoresD=0.355, train_error=0.0667, train_loss=0.00746] \n",
      "Eval: 13: 100%|██████████| 1/1 [00:01<00:00,  1.13s/it, Pearson=0.676, R=0.676, RMSE=0.182, Spearman=0.66, eval_error=0.122, eval_loss=0.0331, scoresA=0.33, scoresB=0.661, scoresC=0.384, scoresD=0.384]\n",
      "Train: 14/30: 100%|██████████| 15/15 [00:08<00:00,  1.84it/s, Pearson=0.951, R=0.951, RMSE=0.0756, Spearman=0.876, scoresA=0.336, scoresB=0.612, scoresC=0.345, scoresD=0.315, train_error=0.0594, train_loss=0.00573]\n",
      "Eval: 14: 100%|██████████| 1/1 [00:01<00:00,  1.17s/it, Pearson=0.646, R=0.646, RMSE=0.189, Spearman=0.641, eval_error=0.134, eval_loss=0.0356, scoresA=0.316, scoresB=0.62, scoresC=0.362, scoresD=0.344]\n",
      "Train: 15/30: 100%|██████████| 15/15 [00:08<00:00,  1.79it/s, Pearson=0.971, R=0.971, RMSE=0.0588, Spearman=0.932, scoresA=0.3, scoresB=0.726, scoresC=0.336, scoresD=0.309, train_error=0.0483, train_loss=0.00348]  \n",
      "Eval: 15: 100%|██████████| 1/1 [00:01<00:00,  1.03s/it, Pearson=0.702, R=0.702, RMSE=0.169, Spearman=0.683, eval_error=0.117, eval_loss=0.0284, scoresA=0.292, scoresB=0.651, scoresC=0.346, scoresD=0.325]\n",
      "Train: 16/30: 100%|██████████| 15/15 [00:08<00:00,  1.83it/s, Pearson=0.97, R=0.97, RMSE=0.0605, Spearman=0.932, scoresA=0.291, scoresB=0.692, scoresC=0.334, scoresD=0.284, train_error=0.0454, train_loss=0.00357]  \n",
      "Eval: 16: 100%|██████████| 1/1 [00:01<00:00,  1.14s/it, Pearson=0.627, R=0.627, RMSE=0.192, Spearman=0.587, eval_error=0.146, eval_loss=0.0369, scoresA=0.28, scoresB=0.599, scoresC=0.326, scoresD=0.3]\n",
      "Train: 17/30: 100%|██████████| 15/15 [00:08<00:00,  1.80it/s, Pearson=0.964, R=0.964, RMSE=0.0656, Spearman=0.899, scoresA=0.264, scoresB=0.665, scoresC=0.307, scoresD=0.253, train_error=0.0525, train_loss=0.00426]\n",
      "Eval: 17: 100%|██████████| 1/1 [00:01<00:00,  1.07s/it, Pearson=0.678, R=0.678, RMSE=0.178, Spearman=0.678, eval_error=0.133, eval_loss=0.0316, scoresA=0.246, scoresB=0.617, scoresC=0.306, scoresD=0.274]\n",
      "Train: 18/30: 100%|██████████| 15/15 [00:08<00:00,  1.82it/s, Pearson=0.97, R=0.97, RMSE=0.0601, Spearman=0.923, scoresA=0.252, scoresB=0.779, scoresC=0.311, scoresD=0.271, train_error=0.0476, train_loss=0.0037]   \n",
      "Eval: 18: 100%|██████████| 1/1 [00:01<00:00,  1.12s/it, Pearson=0.68, R=0.68, RMSE=0.174, Spearman=0.655, eval_error=0.122, eval_loss=0.0302, scoresA=0.234, scoresB=0.678, scoresC=0.3, scoresD=0.268]\n",
      "Train: 19/30: 100%|██████████| 15/15 [00:08<00:00,  1.76it/s, Pearson=0.971, R=0.971, RMSE=0.0605, Spearman=0.921, scoresA=0.25, scoresB=0.764, scoresC=0.306, scoresD=0.239, train_error=0.05, train_loss=0.00366]   \n",
      "Eval: 19: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s, Pearson=0.668, R=0.668, RMSE=0.199, Spearman=0.661, eval_error=0.134, eval_loss=0.0395, scoresA=0.241, scoresB=0.748, scoresC=0.313, scoresD=0.265]\n",
      "Train: 20/30: 100%|██████████| 15/15 [00:08<00:00,  1.83it/s, Pearson=0.941, R=0.941, RMSE=0.0876, Spearman=0.906, scoresA=0.213, scoresB=0.78, scoresC=0.278, scoresD=0.191, train_error=0.0693, train_loss=0.00753] \n",
      "Eval: 20: 100%|██████████| 1/1 [00:01<00:00,  1.19s/it, Pearson=0.7, R=0.7, RMSE=0.21, Spearman=0.684, eval_error=0.145, eval_loss=0.0439, scoresA=0.194, scoresB=0.796, scoresC=0.282, scoresD=0.227]\n",
      "Train: 21/30: 100%|██████████| 15/15 [00:07<00:00,  1.89it/s, Pearson=0.904, R=0.904, RMSE=0.104, Spearman=0.843, scoresA=0.229, scoresB=0.725, scoresC=0.201, scoresD=0.121, train_error=0.0777, train_loss=0.0105]  \n",
      "Eval: 21: 100%|██████████| 1/1 [00:01<00:00,  1.15s/it, Pearson=0.641, R=0.641, RMSE=0.194, Spearman=0.632, eval_error=0.126, eval_loss=0.0375, scoresA=0.216, scoresB=0.761, scoresC=0.215, scoresD=0.151]\n",
      "Train: 22/30: 100%|██████████| 15/15 [00:08<00:00,  1.81it/s, Pearson=0.958, R=0.958, RMSE=0.0724, Spearman=0.911, scoresA=0.197, scoresB=0.728, scoresC=0.161, scoresD=0.0936, train_error=0.051, train_loss=0.00517]\n",
      "Eval: 22: 100%|██████████| 1/1 [00:01<00:00,  1.06s/it, Pearson=0.656, R=0.656, RMSE=0.182, Spearman=0.652, eval_error=0.132, eval_loss=0.033, scoresA=0.185, scoresB=0.694, scoresC=0.171, scoresD=0.115]\n",
      "Train: 23/30: 100%|██████████| 15/15 [00:08<00:00,  1.81it/s, Pearson=0.956, R=0.956, RMSE=0.0736, Spearman=0.908, scoresA=0.201, scoresB=0.773, scoresC=0.134, scoresD=0.092, train_error=0.0542, train_loss=0.00523]\n",
      "Eval: 23: 100%|██████████| 1/1 [00:01<00:00,  1.16s/it, Pearson=0.625, R=0.625, RMSE=0.199, Spearman=0.639, eval_error=0.146, eval_loss=0.0397, scoresA=0.189, scoresB=0.684, scoresC=0.144, scoresD=0.099]\n",
      "Train: 24/30: 100%|██████████| 15/15 [00:08<00:00,  1.82it/s, Pearson=0.92, R=0.92, RMSE=0.0962, Spearman=0.879, scoresA=0.189, scoresB=0.78, scoresC=0.15, scoresD=0.0966, train_error=0.0649, train_loss=0.00893]   \n",
      "Eval: 24: 100%|██████████| 1/1 [00:01<00:00,  1.12s/it, Pearson=0.676, R=0.676, RMSE=0.175, Spearman=0.683, eval_error=0.118, eval_loss=0.0306, scoresA=0.178, scoresB=0.742, scoresC=0.157, scoresD=0.105]\n",
      "Train: 25/30: 100%|██████████| 15/15 [00:08<00:00,  1.80it/s, Pearson=0.964, R=0.964, RMSE=0.0674, Spearman=0.921, scoresA=0.185, scoresB=0.788, scoresC=0.157, scoresD=0.089, train_error=0.0487, train_loss=0.00447] \n",
      "Eval: 25: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it, Pearson=0.656, R=0.656, RMSE=0.182, Spearman=0.637, eval_error=0.122, eval_loss=0.0333, scoresA=0.182, scoresB=0.762, scoresC=0.156, scoresD=0.105]\n",
      "Train: 26/30: 100%|██████████| 15/15 [00:07<00:00,  1.92it/s, Pearson=0.977, R=0.977, RMSE=0.053, Spearman=0.937, scoresA=0.191, scoresB=0.787, scoresC=0.138, scoresD=0.0814, train_error=0.0378, train_loss=0.00275] \n",
      "Eval: 26: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s, Pearson=0.697, R=0.697, RMSE=0.174, Spearman=0.693, eval_error=0.116, eval_loss=0.0304, scoresA=0.174, scoresB=0.746, scoresC=0.152, scoresD=0.099]\n",
      "Train: 27/30: 100%|██████████| 15/15 [00:08<00:00,  1.84it/s, Pearson=0.981, R=0.981, RMSE=0.0484, Spearman=0.932, scoresA=0.178, scoresB=0.758, scoresC=0.142, scoresD=0.0758, train_error=0.0342, train_loss=0.00228]\n",
      "Eval: 27: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s, Pearson=0.673, R=0.673, RMSE=0.175, Spearman=0.675, eval_error=0.122, eval_loss=0.0308, scoresA=0.163, scoresB=0.729, scoresC=0.145, scoresD=0.09]\n",
      "Train: 28/30: 100%|██████████| 15/15 [00:10<00:00,  1.45it/s, Pearson=0.987, R=0.987, RMSE=0.0384, Spearman=0.949, scoresA=0.179, scoresB=0.8, scoresC=0.146, scoresD=0.0789, train_error=0.0288, train_loss=0.00145]  \n",
      "Eval: 28: 100%|██████████| 1/1 [00:01<00:00,  1.98s/it, Pearson=0.699, R=0.699, RMSE=0.171, Spearman=0.693, eval_error=0.113, eval_loss=0.0294, scoresA=0.171, scoresB=0.754, scoresC=0.154, scoresD=0.0947]\n",
      "Train: 29/30: 100%|██████████| 15/15 [00:14<00:00,  1.03it/s, Pearson=0.995, R=0.995, RMSE=0.0265, Spearman=0.956, scoresA=0.182, scoresB=0.793, scoresC=0.151, scoresD=0.0865, train_error=0.0201, train_loss=0.000687]\n",
      "Eval: 29: 100%|██████████| 1/1 [00:01<00:00,  1.59s/it, Pearson=0.687, R=0.687, RMSE=0.175, Spearman=0.688, eval_error=0.114, eval_loss=0.0307, scoresA=0.179, scoresB=0.756, scoresC=0.162, scoresD=0.101]\n",
      "Train: 30/30: 100%|██████████| 15/15 [00:12<00:00,  1.23it/s, Pearson=0.995, R=0.995, RMSE=0.0241, Spearman=0.956, scoresA=0.198, scoresB=0.768, scoresC=0.153, scoresD=0.0798, train_error=0.0177, train_loss=0.000567]\n",
      "Eval: 30: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s, Pearson=0.686, R=0.686, RMSE=0.174, Spearman=0.68, eval_error=0.116, eval_loss=0.0302, scoresA=0.176, scoresB=0.746, scoresC=0.159, scoresD=0.0978]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./model/chinese_wwm_ext/vocab.txt')\n",
    "trainer = Trainer(tokenizer, \"CNSTSX\", \"CNSTSX\", model_name='msim', model_type='siamese', padding_length=150, batch_size=64, batch_size_eval=256, eval_mode='dev', task_name='SAS_CNSTS011001_MSIM')\n",
    "\n",
    "for i in trainer(fct_loss='MSELoss'):\n",
    "    a = i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('pcpower')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e1e097b6c3c5a2a39328ddbc7de6327b7bd71c15618bc750f041eecacee4167"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
