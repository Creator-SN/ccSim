{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 交互式模型训练的样例\n",
    "- model: BERT\n",
    "- dataset: CNSTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.trainer import Trainer\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fct_loss: 损失函数类型, 共有三种`MSELoss`, `BCELoss`, `CrossEntropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./model/chinese_wwm_ext/vocab.txt')\n",
    "trainer = Trainer(tokenizer, \"CNSTS\", \"CNSTS\", padding_length=150, batch_size=64, batch_size_eval=128, eval_mode='dev')\n",
    "\n",
    "for i in trainer(fct_loss='BCELoss'):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Siamese模型训练的样例\n",
    "- model: ESIM\n",
    "- dataset: CNSTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.trainer import Trainer\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./model/chinese_wwm_ext/vocab.txt')\n",
    "trainer = Trainer(tokenizer, \"CNSTS\", \"CNSTS\", model_name=\"esim\",  model_type=\"siamese\", padding_length=150, batch_size=64, batch_size_eval=128, eval_mode='dev', task_name='ESIM_Sim')\n",
    "\n",
    "for i in trainer():\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 交互式模型SAS训练的样例\n",
    "- model: BERT\n",
    "- dataset: CNSTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.sas_trainer import Trainer\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./model/chinese_wwm_ext/vocab.txt')\n",
    "trainer = Trainer(tokenizer, \"CNSTSX\", \"ASAG\", model_name='r2bert', padding_length=256, batch_size=8, batch_size_eval=512, eval_mode='dev', task_name='SAS_ASAG_r2bert')\n",
    "\n",
    "for i in trainer(fct_loss='MSELoss'):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 交互式模型SAS训练的样例\n",
    "- model: MSIM\n",
    "- dataset: CNSTSX\n",
    "\n",
    "最佳参数:\n",
    "- SAS: A + 0.5B + 0.2(C + D)\n",
    "- ASAG: A + B + 0.2(C + D)\n",
    "- SFR: 0.1A + B + 0.2(C + D)\n",
    "- CNSTS: A + B + 0.2(C + D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.sas_trainer import Trainer\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lpc/miniconda3/envs/pcpower/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1642: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  warnings.warn(\n",
      "100%|██████████| 100/100 [00:00<00:00, 14489.10it/s]\n",
      "100%|██████████| 176/176 [00:00<00:00, 16047.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoModel Choose Model: msim\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./save_model/Prompt_SAS/bertlm/bertlm_416/pytorch_model.bin were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at ./save_model/Prompt_SAS/bertlm/bertlm_416/pytorch_model.bin and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]/home/lpc/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/lpc/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:117: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "Train: 1/30: 100%|██████████| 13/13 [00:20<00:00,  1.61s/it, Pearson=-.0294, R=-.0294, RMSE=0.737, Spearman=-.048, scoresA=0.436, scoresB=0.91, scoresC=0.467, scoresD=0.556, train_error=0.649, train_loss=0.546]   \n",
      "Eval: 1: 100%|██████████| 1/1 [00:02<00:00,  2.87s/it, Pearson=-.126, R=-.126, RMSE=0.666, Spearman=-.137, eval_error=0.573, eval_loss=0.444, scoresA=0.428, scoresB=0.906, scoresC=0.469, scoresD=0.561]\n",
      "Train: 2/30: 100%|██████████| 13/13 [00:09<00:00,  1.32it/s, Pearson=-.0891, R=-.0891, RMSE=0.596, Spearman=-.0995, scoresA=0.258, scoresB=0.84, scoresC=0.446, scoresD=0.543, train_error=0.485, train_loss=0.355]\n",
      "Eval: 2: 100%|██████████| 1/1 [00:02<00:00,  2.85s/it, Pearson=-.178, R=-.178, RMSE=0.482, Spearman=-.148, eval_error=0.396, eval_loss=0.232, scoresA=0.239, scoresB=0.832, scoresC=0.448, scoresD=0.538]\n",
      "Train: 3/30: 100%|██████████| 13/13 [00:10<00:00,  1.23it/s, Pearson=-.0526, R=-.0526, RMSE=0.424, Spearman=-.0744, scoresA=0.149, scoresB=0.501, scoresC=0.411, scoresD=0.512, train_error=0.344, train_loss=0.178]\n",
      "Eval: 3: 100%|██████████| 1/1 [00:02<00:00,  2.57s/it, Pearson=0.0158, R=0.0158, RMSE=0.341, Spearman=0.078, eval_error=0.282, eval_loss=0.116, scoresA=0.107, scoresB=0.45, scoresC=0.421, scoresD=0.507]\n",
      "Train: 4/30: 100%|██████████| 13/13 [00:10<00:00,  1.30it/s, Pearson=0.353, R=0.353, RMSE=0.33, Spearman=0.354, scoresA=0.122, scoresB=0.584, scoresC=0.388, scoresD=0.49, train_error=0.273, train_loss=0.109]  \n",
      "Eval: 4: 100%|██████████| 1/1 [00:02<00:00,  2.63s/it, Pearson=0.726, R=0.726, RMSE=0.285, Spearman=0.723, eval_error=0.237, eval_loss=0.0811, scoresA=0.121, scoresB=0.618, scoresC=0.404, scoresD=0.489]\n",
      "Train: 5/30: 100%|██████████| 13/13 [00:10<00:00,  1.29it/s, Pearson=0.767, R=0.767, RMSE=0.254, Spearman=0.773, scoresA=0.145, scoresB=0.561, scoresC=0.387, scoresD=0.466, train_error=0.216, train_loss=0.0652]\n",
      "Eval: 5: 100%|██████████| 1/1 [00:02<00:00,  2.65s/it, Pearson=0.829, R=0.829, RMSE=0.212, Spearman=0.841, eval_error=0.173, eval_loss=0.045, scoresA=0.12, scoresB=0.525, scoresC=0.393, scoresD=0.479]\n",
      "Train: 6/30: 100%|██████████| 13/13 [00:09<00:00,  1.35it/s, Pearson=0.822, R=0.822, RMSE=0.201, Spearman=0.814, scoresA=0.22, scoresB=0.371, scoresC=0.368, scoresD=0.469, train_error=0.173, train_loss=0.0409]\n",
      "Eval: 6: 100%|██████████| 1/1 [00:02<00:00,  2.88s/it, Pearson=0.84, R=0.84, RMSE=0.225, Spearman=0.84, eval_error=0.173, eval_loss=0.0507, scoresA=0.207, scoresB=0.529, scoresC=0.388, scoresD=0.477]\n",
      "Train: 7/30: 100%|██████████| 13/13 [00:09<00:00,  1.31it/s, Pearson=0.882, R=0.882, RMSE=0.17, Spearman=0.878, scoresA=0.134, scoresB=0.231, scoresC=0.369, scoresD=0.459, train_error=0.138, train_loss=0.0284]  \n",
      "Eval: 7: 100%|██████████| 1/1 [00:02<00:00,  2.90s/it, Pearson=0.867, R=0.867, RMSE=0.177, Spearman=0.878, eval_error=0.137, eval_loss=0.0313, scoresA=0.114, scoresB=0.379, scoresC=0.384, scoresD=0.473]\n",
      "Train: 8/30: 100%|██████████| 13/13 [00:10<00:00,  1.28it/s, Pearson=0.915, R=0.915, RMSE=0.145, Spearman=0.91, scoresA=0.131, scoresB=-.14, scoresC=0.354, scoresD=0.46, train_error=0.123, train_loss=0.021]    \n",
      "Eval: 8: 100%|██████████| 1/1 [00:02<00:00,  2.70s/it, Pearson=0.829, R=0.829, RMSE=0.208, Spearman=0.838, eval_error=0.156, eval_loss=0.0433, scoresA=0.177, scoresB=0.248, scoresC=0.384, scoresD=0.475]\n",
      "Train: 9/30: 100%|██████████| 13/13 [00:10<00:00,  1.30it/s, Pearson=0.942, R=0.942, RMSE=0.122, Spearman=0.936, scoresA=0.186, scoresB=0.294, scoresC=0.371, scoresD=0.458, train_error=0.098, train_loss=0.0153] \n",
      "Eval: 9: 100%|██████████| 1/1 [00:02<00:00,  2.73s/it, Pearson=0.858, R=0.858, RMSE=0.174, Spearman=0.86, eval_error=0.129, eval_loss=0.0303, scoresA=0.155, scoresB=0.358, scoresC=0.382, scoresD=0.474]\n",
      "Train: 10/30: 100%|██████████| 13/13 [00:09<00:00,  1.33it/s, Pearson=0.958, R=0.958, RMSE=0.102, Spearman=0.95, scoresA=0.157, scoresB=0.169, scoresC=0.35, scoresD=0.461, train_error=0.083, train_loss=0.0104]    \n",
      "Eval: 10: 100%|██████████| 1/1 [00:02<00:00,  2.81s/it, Pearson=0.873, R=0.873, RMSE=0.174, Spearman=0.878, eval_error=0.131, eval_loss=0.0304, scoresA=0.146, scoresB=0.303, scoresC=0.378, scoresD=0.469]\n",
      "Train: 11/30: 100%|██████████| 13/13 [00:10<00:00,  1.27it/s, Pearson=0.967, R=0.967, RMSE=0.0909, Spearman=0.959, scoresA=0.158, scoresB=0.192, scoresC=0.368, scoresD=0.442, train_error=0.0719, train_loss=0.00828]\n",
      "Eval: 11: 100%|██████████| 1/1 [00:02<00:00,  2.70s/it, Pearson=0.865, R=0.865, RMSE=0.173, Spearman=0.875, eval_error=0.128, eval_loss=0.03, scoresA=0.158, scoresB=0.344, scoresC=0.376, scoresD=0.466]\n",
      "Train: 12/30: 100%|██████████| 13/13 [00:09<00:00,  1.31it/s, Pearson=0.969, R=0.969, RMSE=0.0883, Spearman=0.959, scoresA=0.169, scoresB=0.192, scoresC=0.347, scoresD=0.45, train_error=0.0669, train_loss=0.00773] \n",
      "Eval: 12: 100%|██████████| 1/1 [00:02<00:00,  2.73s/it, Pearson=0.868, R=0.868, RMSE=0.177, Spearman=0.876, eval_error=0.131, eval_loss=0.0314, scoresA=0.184, scoresB=0.438, scoresC=0.373, scoresD=0.463]\n",
      "Train: 13/30: 100%|██████████| 13/13 [00:09<00:00,  1.33it/s, Pearson=0.971, R=0.971, RMSE=0.0867, Spearman=0.962, scoresA=0.152, scoresB=0.0838, scoresC=0.347, scoresD=0.425, train_error=0.0648, train_loss=0.00729]\n",
      "Eval: 13: 100%|██████████| 1/1 [00:02<00:00,  2.78s/it, Pearson=0.858, R=0.858, RMSE=0.183, Spearman=0.874, eval_error=0.136, eval_loss=0.0334, scoresA=0.2, scoresB=0.37, scoresC=0.373, scoresD=0.465]\n",
      "Train: 14/30: 100%|██████████| 13/13 [00:09<00:00,  1.30it/s, Pearson=0.952, R=0.952, RMSE=0.109, Spearman=0.937, scoresA=0.116, scoresB=0.0243, scoresC=0.34, scoresD=0.471, train_error=0.0875, train_loss=0.0117] \n",
      "Eval: 14: 100%|██████████| 1/1 [00:02<00:00,  2.99s/it, Pearson=0.862, R=0.862, RMSE=0.197, Spearman=0.873, eval_error=0.154, eval_loss=0.0388, scoresA=0.118, scoresB=0.265, scoresC=0.369, scoresD=0.46]\n",
      "Train: 15/30: 100%|██████████| 13/13 [00:10<00:00,  1.29it/s, Pearson=0.957, R=0.957, RMSE=0.106, Spearman=0.942, scoresA=0.126, scoresB=0.239, scoresC=0.347, scoresD=0.434, train_error=0.0838, train_loss=0.011] \n",
      "Eval: 15: 100%|██████████| 1/1 [00:02<00:00,  2.55s/it, Pearson=0.878, R=0.878, RMSE=0.177, Spearman=0.886, eval_error=0.133, eval_loss=0.0315, scoresA=0.133, scoresB=0.309, scoresC=0.37, scoresD=0.463]\n",
      "Train: 16/30: 100%|██████████| 13/13 [00:09<00:00,  1.32it/s, Pearson=0.946, R=0.946, RMSE=0.116, Spearman=0.942, scoresA=0.157, scoresB=0.262, scoresC=0.343, scoresD=0.439, train_error=0.0893, train_loss=0.0137]   \n",
      "Eval: 16: 100%|██████████| 1/1 [00:02<00:00,  2.73s/it, Pearson=0.828, R=0.828, RMSE=0.194, Spearman=0.841, eval_error=0.14, eval_loss=0.0374, scoresA=0.142, scoresB=0.489, scoresC=0.365, scoresD=0.458]\n",
      "Train: 17/30: 100%|██████████| 13/13 [00:10<00:00,  1.26it/s, Pearson=0.941, R=0.941, RMSE=0.121, Spearman=0.943, scoresA=0.184, scoresB=0.145, scoresC=0.326, scoresD=0.43, train_error=0.0899, train_loss=0.0142]   \n",
      "Eval: 17: 100%|██████████| 1/1 [00:02<00:00,  2.73s/it, Pearson=0.832, R=0.832, RMSE=0.198, Spearman=0.847, eval_error=0.144, eval_loss=0.0391, scoresA=0.198, scoresB=0.388, scoresC=0.356, scoresD=0.449]\n",
      "Train: 18/30: 100%|██████████| 13/13 [00:10<00:00,  1.29it/s, Pearson=0.942, R=0.942, RMSE=0.118, Spearman=0.928, scoresA=0.129, scoresB=0.205, scoresC=0.297, scoresD=0.402, train_error=0.0858, train_loss=0.0136] \n",
      "Eval: 18: 100%|██████████| 1/1 [00:03<00:00,  3.11s/it, Pearson=0.844, R=0.844, RMSE=0.187, Spearman=0.867, eval_error=0.139, eval_loss=0.0351, scoresA=0.121, scoresB=0.38, scoresC=0.345, scoresD=0.436]\n",
      "Train: 19/30: 100%|██████████| 13/13 [00:09<00:00,  1.33it/s, Pearson=0.976, R=0.976, RMSE=0.0773, Spearman=0.965, scoresA=0.133, scoresB=0.131, scoresC=0.304, scoresD=0.409, train_error=0.0601, train_loss=0.0058] \n",
      "Eval: 19: 100%|██████████| 1/1 [00:03<00:00,  3.01s/it, Pearson=0.851, R=0.851, RMSE=0.194, Spearman=0.877, eval_error=0.145, eval_loss=0.0377, scoresA=0.144, scoresB=0.284, scoresC=0.346, scoresD=0.437]\n",
      "Train: 20/30: 100%|██████████| 13/13 [00:10<00:00,  1.26it/s, Pearson=0.985, R=0.985, RMSE=0.0613, Spearman=0.974, scoresA=0.126, scoresB=0.15, scoresC=0.316, scoresD=0.425, train_error=0.045, train_loss=0.00365]  \n",
      "Eval: 20: 100%|██████████| 1/1 [00:02<00:00,  2.65s/it, Pearson=0.869, R=0.869, RMSE=0.171, Spearman=0.879, eval_error=0.12, eval_loss=0.0294, scoresA=0.169, scoresB=0.406, scoresC=0.35, scoresD=0.444]\n",
      "Train: 21/30: 100%|██████████| 13/13 [00:09<00:00,  1.32it/s, Pearson=0.982, R=0.982, RMSE=0.0693, Spearman=0.968, scoresA=0.135, scoresB=0.199, scoresC=0.297, scoresD=0.429, train_error=0.0519, train_loss=0.00468]\n",
      "Eval: 21: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it, Pearson=0.859, R=0.859, RMSE=0.177, Spearman=0.871, eval_error=0.122, eval_loss=0.0312, scoresA=0.165, scoresB=0.444, scoresC=0.352, scoresD=0.447]\n",
      "Train: 22/30: 100%|██████████| 13/13 [00:05<00:00,  2.25it/s, Pearson=0.981, R=0.981, RMSE=0.0697, Spearman=0.972, scoresA=0.135, scoresB=0.0659, scoresC=0.304, scoresD=0.422, train_error=0.0536, train_loss=0.00475]\n",
      "Eval: 22: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it, Pearson=0.851, R=0.851, RMSE=0.199, Spearman=0.872, eval_error=0.153, eval_loss=0.0395, scoresA=0.136, scoresB=0.292, scoresC=0.342, scoresD=0.432]\n",
      "Train: 23/30: 100%|██████████| 13/13 [00:05<00:00,  2.28it/s, Pearson=0.983, R=0.983, RMSE=0.0664, Spearman=0.974, scoresA=0.142, scoresB=0.233, scoresC=0.313, scoresD=0.429, train_error=0.054, train_loss=0.00439] \n",
      "Eval: 23: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it, Pearson=0.855, R=0.855, RMSE=0.175, Spearman=0.877, eval_error=0.125, eval_loss=0.0308, scoresA=0.14, scoresB=0.438, scoresC=0.35, scoresD=0.443]\n",
      "Train: 24/30: 100%|██████████| 13/13 [00:05<00:00,  2.27it/s, Pearson=0.989, R=0.989, RMSE=0.0552, Spearman=0.977, scoresA=0.141, scoresB=0.156, scoresC=0.304, scoresD=0.431, train_error=0.0403, train_loss=0.00296]\n",
      "Eval: 24: 100%|██████████| 1/1 [00:05<00:00,  5.45s/it, Pearson=0.859, R=0.859, RMSE=0.174, Spearman=0.871, eval_error=0.123, eval_loss=0.0302, scoresA=0.149, scoresB=0.444, scoresC=0.35, scoresD=0.444]\n",
      "Train: 25/30: 100%|██████████| 13/13 [00:09<00:00,  1.35it/s, Pearson=0.994, R=0.994, RMSE=0.0392, Spearman=0.984, scoresA=0.148, scoresB=0.0928, scoresC=0.298, scoresD=0.418, train_error=0.0294, train_loss=0.00151]\n",
      "Eval: 25: 100%|██████████| 1/1 [00:02<00:00,  2.68s/it, Pearson=0.858, R=0.858, RMSE=0.177, Spearman=0.871, eval_error=0.129, eval_loss=0.0315, scoresA=0.143, scoresB=0.378, scoresC=0.346, scoresD=0.439]\n",
      "Train: 26/30: 100%|██████████| 13/13 [00:10<00:00,  1.26it/s, Pearson=0.995, R=0.995, RMSE=0.0366, Spearman=0.985, scoresA=0.13, scoresB=0.135, scoresC=0.307, scoresD=0.41, train_error=0.0271, train_loss=0.00129]  \n",
      "Eval: 26: 100%|██████████| 1/1 [00:02<00:00,  2.76s/it, Pearson=0.859, R=0.859, RMSE=0.174, Spearman=0.871, eval_error=0.125, eval_loss=0.0304, scoresA=0.144, scoresB=0.411, scoresC=0.349, scoresD=0.442]\n",
      "Train: 27/30: 100%|██████████| 13/13 [00:10<00:00,  1.25it/s, Pearson=0.998, R=0.998, RMSE=0.024, Spearman=0.987, scoresA=0.133, scoresB=0.164, scoresC=0.303, scoresD=0.409, train_error=0.0185, train_loss=0.000564] \n",
      "Eval: 27: 100%|██████████| 1/1 [00:02<00:00,  2.66s/it, Pearson=0.86, R=0.86, RMSE=0.174, Spearman=0.875, eval_error=0.125, eval_loss=0.0302, scoresA=0.151, scoresB=0.413, scoresC=0.35, scoresD=0.444]\n",
      "Train: 28/30: 100%|██████████| 13/13 [00:10<00:00,  1.30it/s, Pearson=0.996, R=0.996, RMSE=0.0312, Spearman=0.986, scoresA=0.119, scoresB=0.136, scoresC=0.315, scoresD=0.426, train_error=0.0244, train_loss=0.000949]\n",
      "Eval: 28: 100%|██████████| 1/1 [00:02<00:00,  2.74s/it, Pearson=0.866, R=0.866, RMSE=0.171, Spearman=0.878, eval_error=0.123, eval_loss=0.0292, scoresA=0.14, scoresB=0.39, scoresC=0.349, scoresD=0.442]\n",
      "Train: 29/30: 100%|██████████| 13/13 [00:10<00:00,  1.26it/s, Pearson=0.997, R=0.997, RMSE=0.0275, Spearman=0.987, scoresA=0.127, scoresB=0.139, scoresC=0.315, scoresD=0.424, train_error=0.0216, train_loss=0.000728]\n",
      "Eval: 29: 100%|██████████| 1/1 [00:02<00:00,  2.87s/it, Pearson=0.864, R=0.864, RMSE=0.172, Spearman=0.878, eval_error=0.124, eval_loss=0.0296, scoresA=0.15, scoresB=0.382, scoresC=0.35, scoresD=0.443]\n",
      "Train: 30/30: 100%|██████████| 13/13 [00:10<00:00,  1.28it/s, Pearson=0.996, R=0.996, RMSE=0.0313, Spearman=0.986, scoresA=0.124, scoresB=0.174, scoresC=0.309, scoresD=0.414, train_error=0.0228, train_loss=0.000951]\n",
      "Eval: 30: 100%|██████████| 1/1 [00:02<00:00,  2.67s/it, Pearson=0.865, R=0.865, RMSE=0.171, Spearman=0.878, eval_error=0.122, eval_loss=0.0292, scoresA=0.142, scoresB=0.4, scoresC=0.349, scoresD=0.441]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./model/chinese_wwm_ext/vocab.txt')\n",
    "trainer = Trainer(tokenizer, \"CNSTSX\", \"SASFewShot\", model_name='msim', model_type='siamese', from_pretrained='./save_model/Prompt_SAS/bertlm/bertlm_416/pytorch_model.bin', padding_length=256, batch_size=8, batch_size_eval=256, eval_mode='dev', task_name='SAS_SASFewShot_MSIM_Prompt')\n",
    "\n",
    "for i in trainer(fct_loss='MSELoss'):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SIMCSE 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.cl_trainer import CLTrainer\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('./model/chinese_wwm_ext/vocab.txt')\n",
    "trainer = CLTrainer(tokenizer, \"SIMCSE_STS\", \"SAS\", model_name='simcse', model_type='siamese', padding_length=256, batch_size=16, batch_size_eval=256, eval_mode='dev', task_name='SIMCSE_SAS')\n",
    "\n",
    "for i in trainer(fct_loss='MSELoss'):\n",
    "    a = i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.prompt_trainer import PromptTrainer\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('./model/chinese_wwm_ext/vocab.txt')\n",
    "trainer = PromptTrainer(tokenizer, \"SASPrompt\", \"SASPrompt\", model_name='bertlm', padding_length=256, batch_size=16, batch_size_eval=256, eval_mode='dev', task_name='Prompt_SAS')\n",
    "\n",
    "for i in trainer():\n",
    "    a = i\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('pcpower')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e1e097b6c3c5a2a39328ddbc7de6327b7bd71c15618bc750f041eecacee4167"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
