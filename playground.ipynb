{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `CLS`-交互式模型训练的样例\n",
    "- model: BERT\n",
    "- dataset: CNSTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.trainer import Trainer\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fct_loss: 损失函数类型, 共有三种`MSELoss`, `BCELoss`, `CrossEntropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./model/chinese_wwm_ext/vocab.txt')\n",
    "trainer = Trainer(tokenizer, \"CNSTS\", \"CNSTS\", model_name='r2bert', padding_length=150, batch_size=64, batch_size_eval=128, eval_mode='dev', task_name='STS_CNSTS_r2bert')\n",
    "\n",
    "for i in trainer(fct_loss='MSELoss', gpu=[0]):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `CLS`-Siamese模型训练的样例\n",
    "- model: ESIM\n",
    "- dataset: CNSTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.trainer import Trainer\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./model/chinese_wwm_ext/vocab.txt')\n",
    "trainer = Trainer(tokenizer, \"CNSTSX\", \"CNSTSX\", model_name=\"msim\",  model_type=\"siamese\", padding_length=150, batch_size=64, batch_size_eval=128, eval_mode='dev', task_name='CLS_CNSTSX_msim')\n",
    "\n",
    "for i in trainer(gpu=[0]):\n",
    "    a = i"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `CLS`-AC模型训练的样例\n",
    "- model: ACBert\n",
    "- dataset: CNSTSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.trainer import Trainer\n",
    "from CC.loaders.acSTSLoader import WordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WordTokenizer(vocab_file='./model/chinese_wwm_ext/vocab.txt')\n",
    "trainer = Trainer(tokenizer, \"ACSTS\", \"CNSTSAC\", model_name=\"acbert\", model_type=\"siamese\", padding_length=150, batch_size=64, batch_size_eval=128, eval_mode='dev', task_name='CLS_CNSTSAC_acbert_simcse_entity_19925')\n",
    "\n",
    "for i in trainer(gpu=[0], lr=2e-5):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `CLS`-交互式模型预测的样例\n",
    "- model: BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.predictor import Predictor\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./model/chinese_wwm_ext/vocab.txt')\n",
    "predictor = Predictor(tokenizer, model_name=\"bert\",  padding_length=256, resume_path='./save_model/Sim/bert/bert_7500.pth', batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in predictor([['你好', '我很好']]):\n",
    "    a = i\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `SAS训练`交互式模型的样例\n",
    "- model: BERT\n",
    "- dataset: CNSTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.sas_trainer import Trainer\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./model/chinese_wwm_ext/vocab.txt')\n",
    "trainer = Trainer(tokenizer, \"CNSTSX\", \"CNSTSX\", model_name='bert', padding_length=150, batch_size=16, batch_size_eval=512, eval_mode='dev', task_name='SAS_CNSTSX_bert')\n",
    "\n",
    "for i in trainer(fct_loss='MSELoss'):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `SAS训练`Siamese模型的样例\n",
    "- model: SBERT\n",
    "- dataset: CNSTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.sas_trainer import Trainer\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./model/chinese_wwm_ext/vocab.txt')\n",
    "trainer = Trainer(tokenizer, \"CNSTSX\", \"CNSTSX\", model_name='bimpm', model_type='siamese', padding_length=100, batch_size=32, batch_size_eval=512, eval_mode='dev', task_name='SAS_CNSTSX_bimpm')\n",
    "\n",
    "for i in trainer(fct_loss='MSELoss', lr=1e-3):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `SAS训练`MSIM模型的样例\n",
    "- model: MSIM\n",
    "- dataset: CNSTSX\n",
    "\n",
    "最佳参数:\n",
    "- SAS: A + B + 0.2(C + D)\n",
    "- ASAG: A + B + 0.2(C + D)\n",
    "- SFR: 0.1A + B + 0.2(C + D)\n",
    "- CNSTS: A + B + 0.2(C + D)\n",
    "\n",
    "FewShot最佳参数:\n",
    "- SAS: A + B + 0.2(C + D)\n",
    "- ASAG: 0.1A + 0.8B + 0.2(C + D)\n",
    "\n",
    "Fewshot Prompt Fine-tuning时 ASAG数据集需要1e-4学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.sas_trainer import Trainer\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./model/chinese_wwm_ext/vocab.txt')\n",
    "trainer = Trainer(tokenizer, \"CNSTSX\", \"SFR\", model_name='msim', model_type='siamese', padding_length=256, batch_size=8, batch_size_eval=256, eval_mode='dev', task_name='SAS_SFR_msim')\n",
    "\n",
    "for i in trainer(fct_loss='MSELoss'):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `SIMCSE` 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.cl_trainer import CLTrainer\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('./model/chinese_wwm_ext/vocab.txt')\n",
    "trainer = CLTrainer(tokenizer, \"CL\", \"RemixCL\", model_name='simcse', model_type='siamese', from_pretrained='./save_model/SIMCSE_RemixCL/simcse/simcse_11955/pytorch_model.bin', padding_length=256, batch_size=64, batch_size_eval=256, eval_mode='dev', task_name='SIMCSE_RemixCL')\n",
    "\n",
    "for i in trainer(fct_loss='MSELoss', gpu=[0]):\n",
    "    a = i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.prompt_trainer import PromptTrainer\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('./model/chinese_wwm_ext/vocab.txt')\n",
    "trainer = PromptTrainer(tokenizer, \"SASPrompt\", \"ASAGPrompt\", model_name='bertlm', padding_length=256, batch_size=16, batch_size_eval=256, eval_mode='dev', task_name='Prompt_ASAG')\n",
    "\n",
    "for i in trainer():\n",
    "    a = i\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('pcpower')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e1e097b6c3c5a2a39328ddbc7de6327b7bd71c15618bc750f041eecacee4167"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
